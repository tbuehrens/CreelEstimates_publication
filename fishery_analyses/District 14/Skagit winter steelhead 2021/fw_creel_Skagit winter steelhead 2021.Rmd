---
title: "Freshwater Creel Estimates"
date: "`r Sys.Date()`"
params:
  project_name: "District 14"
  fishery_name: "Skagit winter steelhead 2021"
  est_date_start: "2021-02-01"
  est_date_end: "2021-04-13"
  est_catch_groups: !r data.frame(
    rbind(c(species = 'Steelhead', life_stage = 'NA', fin_mark = 'UM', fate = 'Released'))
    )
  person_count_type: "angler"
  period_pe: "week"
  period_bss: "day"
  days_wkend: !r c('Saturday', 'Sunday')
  index_count_types: "Vehicle/Trailers Only"
  census_expansion: "Direct"
  day_length_expansion: "night closure"
  min_fishing_time: 0.5
  output_location_filepath: "local"
output:
  html_document:
    fig_caption: yes
    theme: default
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
#running the 'setup' chunk loads the read-only `params` list
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.width = 10, fig.height = 8)
library("here") #defines root at working dir of .Rproj
```

```{r first_time_run, eval=FALSE, include=FALSE}
# set up file paths
## top level for scripts and outputs
# if (!dir.exists(here("fishery_analyses"))) {
#   dir.create(here("fishery_analyses")); "fishery_analyses folder created"
# }
# ## project level
# if (!dir.exists(here("fishery_analyses", params$project_name))) {
#   dir.create(here("fishery_analyses", params$project_name))
#   paste(here("fishery_analyses", params$project_name), "folder created")
# }
# ## fishery-specific
# if (!dir.exists(here("fishery_analyses", params$project_name, params$fishery_name))) {
#   dir.create(here("fishery_analyses", params$project_name, params$fishery_name))
#   paste(here("fishery_analyses", params$project_name, params$fishery_name), "folder created")
# }
# 
# # evaluate if analysis .Rmd already exists, if not then generate new file 
# if (file.exists(here("fishery_analyses", params$project_name, params$fishery_name, 
#        paste0("fw_creel_", params$fishery_name, ".Rmd")))) {
#   
#   print("Analysis .Rmd file already exists")
#   
# } else {
# #save the master template with new params arguments for the fishery
# rstudioapi::documentSave(rstudioapi::getActiveDocumentContext()$id)
# #make an appropriately renamed copy
# file.copy(
#   here("template_scripts/fw_creel.Rmd"),
#   here("fishery_analyses", params$project_name, params$fishery_name, 
#        paste0("fw_creel_", params$fishery_name, ".Rmd"))
# )
# #open the new copy
# rstudioapi::documentOpen(
#   here("fishery_analyses", params$project_name, params$fishery_name, 
#        paste0("fw_creel_", params$fishery_name, ".Rmd"))
# )
# }

```

```{r packages_and_functions}
library("suncalc")
library("tidyverse")
library("patchwork")
library("gt")
theme_set(theme_light())

library("rstan")
rstan_options(auto_write = TRUE)

purrr::walk(list.files(here("R_functions"), full.names = T), source)
```

# `r paste(params$fishery_name)`

```{r}
gt(tibble(param = names(params), value = as.character(params)))
```

# Set day length times if using manual option 

```{r day_length_inputs, echo = FALSE}

day_length_inputs <- list()

if(params$day_length_expansion == "manual"){
# Step #1: Select general strategy for [earliest] start and [latest] end time
    day_length_inputs$start_time<-c("manual") # enter either "sunrise" or "manual" 
    day_length_inputs$end_time<-c("sunset")    # enter either "sunset"  or "manual" 
  # Step #2A: If necessary, specify an offset (in hours) to the start and end times
    # (e.g., if legal fishing occurs 1 hr. prior to sunrise & sunset, enter 1 below for both); enter 0 if no offset needed
    day_length_inputs$start_adj<-c(1) # Specify an offset for the start time (in hours);    
    day_length_inputs$end_adj<-c(1)   # Specify an offset for the end time (in hours);  
  # Step #2B: If "manual" entered for "ui_start_time" or "ui_end_time", enter the earliest start and/or latest end time for a creel survey event
    day_length_inputs$start_manual<-c("06:00:00") # Specify manual start time (format "HH:MM:SS", e.g., 6 AM = "06:00:00")
    day_length_inputs$end_manual<-  c() # Specify manual end time (format "HH:MM:SS")  
}
```

# Fetch raw data

```{r dwg_fetch, echo=FALSE}
dwg <- fetch_dwg(params$fishery_name)

dwg$days <- prep_days(
  date_begin = params$est_date_start, 
  date_end = params$est_date_end, 
  weekends = params$days_wkend,
  holidays = read_lines(paste(here(), "input_files/dates_holidays_2015_2030.txt", sep = "/")),
  lat = mean(dwg$ll$centroid_lat), #can/should consider smarter options
  long = mean(dwg$ll$centroid_lon),#can/should consider smarter options 
  period_pe = params$period_pe,
  sections = unique(dwg$effort$section_num),
  closures = dwg$closures,
  day_length = params$day_length_expansion,
  day_length_inputs = day_length_inputs
  )
```

# Review fetched data

## Fishery sections

```{r table_sections}
dwg$effort |> 
  filter(location_type == "Section") |> 
  distinct(water_body, section_num, location) |> 
  arrange(section_num) |>
  select(`Water Body` = water_body, `Section Number` = section_num, `Location description` = location) |> 
  gt()
```

## Days

```{r gt_creel_days}
dwg$days |> 
  mutate(across(starts_with("open_"), ~if_else(., "open","closed"))) |> 
  rename_with(.cols = starts_with("open_"), .fn = ~str_remove_all(., "open_")) |> 
  gt::gt() |> 
  gt::data_color(
    columns = contains("section_"),
    colors = scales::col_factor(
      palette = c("#C3C7C3", "#78B574"),
      domain = c("closed","open")) 
  )

```

## Period-Dates reference
```{r gt_period_dates_reference}

# reference for period (time_strata)

dwg$days |> 
    group_by(period) |> 
    summarise(
      min_event_date = min(event_date),
      max_event_date = max(event_date)) |> 
  gt::gt(caption = "Reference table containing the first and last date within each time stratum period in the monitoring period.")

```

## Effort

```{r gt_creel_effort}
dwg$effort |>
  filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))) |> 
  distinct(section_num, location, event_date, tie_in_indicator, count_sequence) |> 
  count(section_num, location, tie_in_indicator) |> 
  mutate(tie_in_indicator = case_when(
    tie_in_indicator == 1 ~ "census",
    tie_in_indicator == 0 ~ "index"
  )) |>
  arrange(section_num, tie_in_indicator, location) |> 
  gt(groupname_col = "section_num", rowname_col = "location") |> 
  tab_style(
    style = list(cell_fill("grey70"), cell_text(weight = "bold")),
    locations = cells_body(rows = tie_in_indicator == "census")
  )
```

## Interview

```{r gt_creel_interview}
# dwg$interview |>  
#   filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))) |> 
#   count(section_num, fishing_location) |> 
#   arrange(section_num) |> 
#   gt(groupname_col = "section_num", caption = "Number of interviews by analysis section")

dwg$interview |>  
  filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))) |> 
  count(section_num, event_date) |> 
  pivot_wider(names_from = section_num, values_from = n) |> 
  arrange(event_date) |> 
  gt(rowname_col = "event_date") |> 
  sub_missing() |> 
  data_color(
    columns = where(is.numeric),
    colors = scales::col_quantile(
      palette = c("white", "orange"), 
      reverse = T, na.color = "grey",
      domain = NULL #c(0, )
    )
  )
```

## Catch

```{r gt_creel_catch}
dwg$catch |>
  left_join(dwg$interview, by = "interview_id") |> 
  filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))) |> 
  group_by(catch_group) |> 
  summarise(fish_count = sum(fish_count), .groups = "drop") |> 
  gt(caption = "Total reported encounters in interviews to date for catch groups defined as individual combinations of species, life state, fin mark, and fate")
```

# Shared data aggregation

```{r prep_dwg_summ_shared_summary_objects, echo=FALSE, results = 'hide'}
dwg_summ <- list() #intermediate objects wrangled from creel list elements

#get count_type levels from interview to ensure alignment...?

#prep_interview() no longer excludes observations with NA vehicle_count/trailer_count
#requires handling during summarization for fisheries/records where these were not collected
dwg_summ$interview <- prep_dwg_interview(
  dwg_interview = dwg$interview |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))),
  dwg_catch = dwg$catch,
  person_count_type = params$person_count_type,
  min_fishing_time = params$min_fishing_time,
  est_catch_groups = params$est_catch_groups 
  )

#Aggregates census (tie in) effort counts, associating to closest-in-time index count
dwg_summ$effort_census <- prep_dwg_effort_census(
  eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))))

#Aggregates index effort counts over locations within count_seq & section
dwg_summ$effort_index <- prep_dwg_effort_index(
  eff = dwg$effort |> filter(between(event_date, as.Date(params$est_date_start), as.Date(params$est_date_end))))

```

## Index effort counts

```{r plot_index_effort_counts, fig.cap= "Index effort counts for each count sequence on surveyed days within the monitoring period."}
# plot of index effort counts faceted by section and count_type per count sequence and day 
plot_inputs_pe_index_effort_counts(effort_index = dwg_summ$effort_index)
```

# PE estimation

```{r prep_inputs_pe, results = 'hide'}
inputs_pe <- list()

#derive a table of potentially section-anglerType-specific values to modify census expansions
inputs_pe$census_expan <- prep_inputs_pe_census_expan(eff = dwg$effort, census_expansion = params$census_expansion)

# Calculate total days the fishery was open per strata (strata = period, day_type, and section_num)
inputs_pe$days_total <- prep_inputs_pe_days_total(days = dwg$days)

# depending on the types of index counts, reach the calc: ang_hrs_daily_mean_TI_expan = angler_hours_daily_mean * TI_expan_final
# when index counts are already bank & boat, matching census counts,
#   then angler_hour daily means are just effort index counts of anglers expanded by day length,
#   which are multiplied against tie-in expanded census counts of anglers by type (per section_num)
# but when index counts are trailers & vehicles,
#   then angler_hour daily means require first using interviews to estimate anglers_per_vhcl_trlr by angler_final total & boat 
#   so anglers_per_vhcl_trlr can be multiplied against the trailer & vehicle counts in effort_index, releveled to boat/total
#   and then TI-expanded counts similarly require splitting, re-leveling and rebinding census to boat/total to allow join with effort_index
#   and THEN generating a final object with total, boat and derived-bank, including dealing with case of only-bank (e.g., Cascade)
if(str_detect(params$index_count_types, "Bank|Boat")) {
  
  inputs_pe$ang_hrs_daily_mean <- prep_inputs_pe_ang_hrs_bank_boat(
    days = dwg$days, 
    dwg_summarized = dwg_summ,
    census_expan = inputs_pe$census_expan
    )
  
} else if(str_detect(params$index_count_types, "Vehicle|Trailer")) {
  
  #could skip retaining as list element and just pass as inline call in arg to next function
  inputs_pe$interview_ang_per_vhcl_trlr <- prep_inputs_pe_int_ang_per_vhcl_trlr(dwg_summarized = dwg_summ)
  
  # returns season-long total of counts for paired census and index counts
  inputs_pe$paired_census_index_counts <- prep_inputs_pe_paired_census_index_counts(
  days = dwg$days,
  dwg_summarized = dwg_summ,
  interview_ang_per_vehic = inputs_pe$interview_ang_per_vhcl_trlr,
  census_expan = inputs_pe$census_expan)
  
  # returns census-corrected daily mean angler hours 
  inputs_pe$ang_hrs_daily_mean <- prep_inputs_pe_ang_hrs_vhcl_trlr(
    days = dwg$days, 
    dwg_summarized = dwg_summ,
    interview_ang_per_vehic = inputs_pe$interview_ang_per_vhcl_trlr,
    paired_census_index_counts = inputs_pe$paired_census_index_counts,
    census_expan = inputs_pe$census_expan
    )
  
}

#aggregate interviews per day per strata of [week/month-weekend/day-section_num-bank/boat-est_cg]
#then multiply by TI-expanded effort estimate
#dropping any date-section_num-angler_final-catch_groups for which only interview-based CPUE is available
#but census-corrected effort estimates are not (various reasons why a day-section_num-angler_final hours could be NA)
inputs_pe$daily_cpue_catch_est <- prep_inputs_pe_daily_cpue_catch_est(
  days = dwg$days,
  dwg_summarized = dwg_summ,
  angler_hours_daily_mean = inputs_pe$ang_hrs_daily_mean
)

#THIS SEEMS WRONG/MISSING STRATA:  dplyr::group_by(section_num, angler_final)
inputs_pe$df <- prep_inputs_pe_df(
  days = dwg$days,
  angler_hours_daily_mean = inputs_pe$ang_hrs_daily_mean
)

```

## Paired census and index angler effort count surveys

```{r view_paired_census_index_counts, fig.cap= "Scatterplot displaying the effort bias-term ratio (TI_expan_final) for each section and angler type (angler_final), representing the total count from census surveys divided by the total count from index surveys. A 1:1 relationship is shown by the dashed line." }

# table view of census / index surveys and resulting bias term ratio 
inputs_pe$paired_census_index_counts |> 
  select(section_num, angler_final, count_census, count_index, TI_expan_final) |> 
  gt(caption = "The season-long sum of paired census and index angler effort counts and corresponding bias-term ratio (TI_expan_final), indicating the magnitude and direction (postive or negative) of bias in index counts relative to census counts") |> 
  fmt_number(count_index, decimals = 0) |> 
  fmt_number(TI_expan_final, decimals = 2)

# scatterplot of total census counts vs. total index counts by angler type and section 
plot_inputs_pe_census_vs_index(census_TI_expan = inputs_pe$paired_census_index_counts)

```


```{r estimates_pe}
estimates_pe <- list() 

estimates_pe$effort <- est_pe_effort(
  days = dwg$days,
  pe_inputs_list = inputs_pe
)

estimates_pe$catch <- est_pe_catch(
  days = dwg$days,
  pe_inputs_list = inputs_pe
)
 

# Next steps - 3.) update "inputs_pe$census_expan" object -- currenlty not using the indirect census expansion values from database due to naming issue in database (i.e., direct_census_bank should be indirect_census_boat) and ability/use of pivot_wider function to handle column header prefixes.

```

## Summary PE

### Effort estimates
```{r PE_effort_summary}

# effort by section_num

 estimates_pe$effort |>
        group_by(section_num) |> 
        summarise(
          E_sum = sum(est, na.rm=T),
          .groups = "drop"
        ) |> 
  pivot_wider(names_from = section_num, values_from = E_sum) |>
  gt(caption = paste("Estimated effort (angler hours) by fishing section from", params$est_date_start, "to", params$est_date_end))

```

```{r plot_pe_effort_estimates, fig.cap= "Estimated effort (angler-hours) grouped by time strata, section and angler type (angler_final)."}
# barplot of effort estimates by time stratum, section, and angler type
plot_est_pe_effort(estimates_pe_effort = estimates_pe$effort,
                   period_pe = params$period_pe)

```
### Catch rate (CPUE) estimates

```{r pe_cpue_period_plots, results = 'hide'}

pe_cpue_period_plots <- unique(inputs_pe$daily_cpue_catch_est$est_cg) |> 
  set_names() |> 
  map(
    ~plot_inputs_pe_cpue_period(
      days = dwg$days,
      dwg_summarized = dwg_summ,
      daily_cpue_catch_est = inputs_pe$daily_cpue_catch_est,
      est_catch_group = .x,
      period_pe = params$period_pe)
  )
      
pe_cpue_period_plots

```

Estimated catch per unit effort (fish/hour) grouped by catch group, period, section, angler type, and day-type. 

### Catch estimates

```{r PE_catch_summary}

estimates_pe$catch |> 
        group_by(est_cg, section_num) |>
        summarise(
          C_sum = sum(est),
          .groups = "drop"
        ) |> 
      pivot_longer(
        cols = -c(est_cg, section_num),
        names_to = "estimate",
        values_to = "PE"
      ) |> 
  select(est_cg, section_num, estimate, PE, everything()) |> 
  gt(groupname_col = "est_cg", caption = "Total estimates of catch during the monitoring period for each fish catch group.") |>
  fmt_number(-c(estimate, est_cg, section_num), decimals = 1) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  )
```


```{r plot_pe_catch_estimates, results = 'hide'}
# barplot of catch estimates by catch group, time stratum, section, and angler type

pe_catch_est_plots <- unique(estimates_pe$catch$est_cg) |> 
  set_names() |> 
  map(
    ~plot_est_pe_catch(
      estimates_pe_catch = estimates_pe$catch,
      est_catch_group = .x,
      period_pe = params$period_pe)
  )
      
pe_catch_est_plots
```

Estimated catch grouped by catch group, period, section, angler type,and day type. 

# BSS estimation

```{r prep_inputs_bss, eval=FALSE}
if(!exists(file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_data_", params$fishery_name, ".rds")))){
  #either a single element list for a single catch_group
  #or a list of bss-input-lists, one for each catch_group
  inputs_bss <- unique(dwg_summ$interview$est_cg) |> 
    set_names() |> 
    map(
      ~prep_inputs_bss(
        est_catch_group = .x,
        period = params$period_bss,
        days = dwg$days,
        dwg_summarized = dwg_summ,
        #likely warrants revision? targeting n-gears-rows by n-sections-cols matrix of values
        tie_in_mat = dwg$effort |> 
          filter(tie_in_indicator == 1) |> 
          distinct(section_num, p_census_bank, p_census_boat) |> 
          pivot_longer(starts_with("p_census"), names_to = "ang", values_to = "val") |> 
          arrange(section_num) |> 
          pivot_wider(names_from = section_num, values_from = val) |> 
          select(-ang) |> 
          as.matrix(),
        priors = c(
          value_cauchyDF_sigma_eps_C = 0.5,
          value_cauchyDF_sigma_eps_E = 0.5,
          value_cauchyDF_sigma_r_E = 0.5,  
          value_cauchyDF_sigma_r_C = 0.5,  
          value_cauchyDF_sigma_mu_C = 0.5, 
          value_cauchyDF_sigma_mu_E = 0.5, 
          value_normal_sigma_omega_C_0 = 1,
          value_normal_sigma_omega_E_0 = 3,
          value_lognormal_sigma_b = 1,
          value_normal_sigma_B1 = 5,  
          value_normal_mu_mu_C = log(0.02),
          value_normal_sigma_mu_C = 1.5,  
          value_normal_mu_mu_E = log(5),
          value_normal_sigma_mu_E = 2,  
          value_betashape_phi_E_scaled = 1, 
          value_betashape_phi_C_scaled = 1 
        )
      )
    )
  saveRDS(inputs_bss,file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_data_", params$fishery_name, ".rds")))
}else(
  inputs_bss <- readRDS(file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_data_", params$fishery_name, ".rds")))
)

```

```{r estimates_bss, eval=FALSE}
#should work for either single or multiple catch_group 
estimates_bss <- list()

for(ecg in names(inputs_bss)) {
  gc(verbose = TRUE)
  
  bss_fit_file <- file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_fit_", params$fishery_name, ".rds"))
  
  if (!file.exists(bss_fit_file)) {
    ecg_fit <- fit_bss(
      bss_inputs_list = inputs_bss[[ecg]],
      n_chain = 4,  
      n_cores = 4,
      n_iter = 200,
      n_warmup = 100,
      n_thin = 1,
      adapt_delta = 0.8,
      max_treedepth = 10,
      init = "0"
    )
    
    saveRDS(ecg_fit, bss_fit_file)
  } else {
    ecg_fit <- readRDS(bss_fit_file)
  }
  
  ecg_keep <- list()
  
  ecg_keep$overview <- get_bss_overview(bss_fit = ecg_fit, ecg = ecg)
  
  ecg_keep$cpue_daily <- get_bss_cpue_daily(bss_fit = ecg_fit, ecg = ecg)
  
  ecg_keep$catch_daily <- get_bss_catch_daily(bss_fit = ecg_fit, ecg = ecg)
  
  ecg_keep$effort_daily <- get_bss_effort_daily(bss_fit = ecg_fit, ecg = ecg)
  
  ecg_keep$draws <- extract(ecg_fit)
  
  estimates_bss[[ecg]] <- ecg_keep
  
  rm(ecg_fit, ecg_keep); gc()
}

```

## summary BSS

```{r BSS_summary, eval= FALSE}

# effort by section_num

map_df(estimates_bss, ~.x$overview) |> 
  gt(groupname_col = "est_cg") |>
  fmt_number(-c(estimate, est_cg), decimals = 1) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "50%")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "50%")
  )

```


## plot probability density function of effort and catch 

```{r, eval=FALSE}

season_results <- map_df(estimates_bss, ~.x$draws$C_sum) |> 
  mutate(iter = row_number()) |> 
  pivot_longer(cols = -(iter), names_to = "est_cg", values_to = "C_sum")

map_df(estimates_bss, ~.x$draws$C_sum) |> 
  mutate(iter = row_number()) |> 
  pivot_longer(cols = -(iter), names_to = "est_cg", values_to = "C_sum") |> 
  ggplot(aes(x=C_sum,fill=C_sum)) +
  facet_wrap(~ est_cg, ncol=1,scales = 'free') +
  theme_bw() +
  geom_density() +
  ylab(NULL) +
  geom_vline(
    season_results |> 
      group_by(est_cg) |> 
      summarise(C_sum = quantile(C_sum, c(0.025, 0.5, 0.975)), q = c(0.025, 0.5, 0.975)), mapping=aes(xintercept=C_sum,group=est_cg),linetype="dashed") +
theme(legend.title = element_blank())
    
```



## plot daily catch BSS

```{r, eval=FALSE}

map_df(estimates_bss, ~.x$catch_daily) |> 
    ggplot(aes(x = event_date, y = `50%`, fill = angler_final, color = angler_final)) +
    geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), alpha = 0.2, color = "transparent") +
    geom_line(lwd = 1) +
    ylab("Median (50%) catch") +
    xlab("Date") +
    labs(color = "Angler type", fill = "Angler type") +
    scale_x_date() +
    theme_bw() +
    facet_wrap(~section_num + est_cg)

```


## plot daily effort BSS

```{r,  eval=FALSE}

estimates_bss[[1]]$effort_daily |> 
    ggplot(aes(x = event_date, y = `50%`, fill = angler_final, color = angler_final)) +
    geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), alpha = 0.2, color = "transparent") +
    geom_line(lwd = 1) +
    ylab("Median (50%) effort (angler hours)") +
    xlab("Date") +
    labs(color = "Angler type", fill = "Angler type") +
    scale_x_date() +
    theme_bw() +
    facet_wrap(~section_num, nrow = estimates_bss[[1]]$effort_daily$section_num |> n_distinct())


```


## plot daily CPUE BSS

```{r, eval=FALSE}

map_df(estimates_bss, ~.x$cpue_daily) |> 
    ggplot(aes(x = event_date, y = `50%`, fill = angler_final, color = angler_final)) +
    geom_ribbon(aes(ymin = `2.5%`, ymax = `97.5%`), alpha = 0.2, color = "transparent") +
    geom_line(lwd = 1) +
    ylab("Median (50%) catch per unit effort (fish/hour") +
    xlab("Date") +
    labs(color = "Angler type", fill = "Angler type") +
    scale_x_date() +
    theme_bw() +
    facet_wrap(~section_num + est_cg)

```


# PE/BSS combined summary

```{r combo_overview, eval=FALSE}
#per-est_cg summary of total effort hours and catch/encounters, showing results of both PE and BSS estimation methods

map_df(estimates_bss, ~.x$overview) |> 
  left_join(
    bind_cols(
      estimates_pe$catch |> 
        group_by(est_cg) |>
        summarise(
          C_sum = sum(est),
          .groups = "drop"
        ),
      estimates_pe$effort |> 
        summarise(
          E_sum = sum(est, na.rm=T),
          .groups = "drop"
        )
    ) |> 
      pivot_longer(
        cols = -est_cg,
        names_to = "estimate",
        values_to = "PE"
      )
    ,
    by = c("estimate", "est_cg")
  ) |> 
  select(est_cg, estimate, PE, everything()) |> 
  gt(groupname_col = "est_cg") |>
  fmt_number(-c(estimate, est_cg), decimals = 1) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "PE")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "50%")
  ) |> 
  tab_style(
    style = cell_fill(), locations = cells_body(columns = "50%")
  )

```


# Save results

```{r write_out_results, eval = FALSE}
# bss_overview <- estimates_bss$summary_by_catchgroup
#write out a workbook with results from model runs 


## how to write out html to outputs file path??

# data fetched from dwg and summarized data used for PE and BSS (dwg_summ)
if(nchar(params$output_location_filepath) > 1) {
  writexl::write_xlsx(
  c(set_names(dwg, paste0("dwg_", names(dwg))), set_names(dwg_summ, paste0("dwg_summ", names(dwg_summ)))),
  path = file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("fetch_dwg_", params$fishery_name, ".xlsx"))
  )
}

# PE output
if(nchar(params$output_location_filepath) > 1) {
  writexl::write_xlsx(
  c(estimates_pe[rev(names(estimates_pe))]),
  path = file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("pe_output_", params$fishery_name, ".xlsx"))
  )
}

# overview of BSS output
# if(nchar(params$output_location_filepath) > 1) {
#   writexl::write_xlsx(bss_overview,
#   path = file.path(where("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_overview_", params$fishery_name, ".xlsx"))
#   )
# }
```


## Posterior Predictive Check for BSS
```{r PPC, eval = FALSE}
library(bayesplot)

stan_fit<-readRDS(file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_fit_", params$fishery_name, ".rds")))
#write.csv(summary(stan_fit)$summary,file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_summary_", params$fishery_name, ".csv")))

# stan_fit<-readRDS(file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_fit_", params$fishery_name, "_ZINB.rds")))
# 
# write.csv(summary(stan_fit)$summary,file.path(here("fishery_analyses", params$project_name, params$fishery_name), paste0("bss_summary_", params$fishery_name, "_ZINB.csv")))

# Perform posterior predictive checks
V_I_PPC<-as.data.frame(apply(extract(stan_fit)$V_I_rep,2, function(x) quantile(x, c(0.025,0.975))))%>%
  rownames_to_column(var="Quantile")%>%
  as_tibble()%>%
  pivot_longer(names_to = "names",values_to = "V_I",cols = c(-Quantile))%>%
  pivot_wider(names_from = Quantile,values_from = V_I)%>%
  bind_cols(tibble(V_I=inputs_bss[[ecg]]$V_I,
                   section=inputs_bss[[ecg]]$section_V,
                   day = inputs_bss[[ecg]]$day_V,
                   countnum = inputs_bss[[ecg]]$countnum_V
                   )
  )%>%
  mutate(section = as.factor(section),
         day = as.factor(day),
         countnum = as.factor(countnum),
         fit = factor(ifelse(V_I>=`2.5%` & V_I<=`97.5%`,"fit","no fit"))
         )

bayes_p<-V_I_PPC %>%
  group_by(section) %>%
  summarise(
    fit_count = sum(fit == "fit"),
    no_fit_count = sum(fit == "no fit"),
    total_count = fit_count + no_fit_count,
    bayes_p = ifelse(no_fit_count == 0, 1, fit_count / total_count)
  ) %>%
  ungroup()%>%
  add_row(section = "Total",
          fit_count = sum(.$fit_count),
          no_fit_count = sum(.$no_fit_count),
          total_count = sum(.$total_count),
          bayes_p = ifelse(sum(.$no_fit_count) == 0, 1, sum(.$fit_count) / sum(.$total_count))
  ) %>%
  mutate(Parameter = "V_I_PPC")



p<-ggplot(V_I_PPC, aes(x = V_I, y = V_I, color=section)) +
  facet_grid(cols=vars(section)) +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0) +
  labs(x = "Observed V_I", y = "95% PPI") +
  geom_line(color="black") +
  ylim(0, max(V_I_PPC$`97.5%`)) +
  xlim(0, max(V_I_PPC$`97.5%`)) + 
  theme_classic()


ggsave(filename=file.path(here("fishery_analyses", params$project_name, params$fishery_name), "V_I_PPC.png"),
       plot = p,
       width = 6.5, height = 6.5, dpi = 300, limitsize = TRUE,
       scale=1.75,
       units = c("in")
       )


T_I_PPC<-as.data.frame(apply(extract(stan_fit)$T_I_rep,2, function(x) quantile(x, c(0.025,0.975))))%>%
  rownames_to_column(var="Quantile")%>%
  as_tibble()%>%
  pivot_longer(names_to = "names",values_to = "T_I",cols = c(-Quantile))%>%
  pivot_wider(names_from = Quantile,values_from = T_I)%>%
  bind_cols(tibble(T_I=inputs_bss[[ecg]]$T_I,
                   section=inputs_bss[[ecg]]$section_T,
                   day = inputs_bss[[ecg]]$day_T,
                   countnum = inputs_bss[[ecg]]$countnum_T
                   )
  )%>%
  mutate(section = as.factor(section),
         day = as.factor(day),
         countnum = as.factor(countnum),
         fit = factor(ifelse(T_I>=`2.5%` & T_I<=`97.5%`,"fit","no fit"))
         )

bayes_p<-bayes_p%>%
  bind_rows(T_I_PPC %>%
    group_by(section) %>%
    summarise(
      fit_count = sum(fit == "fit"),
      no_fit_count = sum(fit == "no fit"),
      total_count = fit_count + no_fit_count,
      bayes_p = ifelse(no_fit_count == 0, 1, fit_count / total_count)
    ) %>%
    ungroup()%>%
    add_row(section = "Total",
            fit_count = sum(.$fit_count),
            no_fit_count = sum(.$no_fit_count),
            total_count = sum(.$total_count),
            bayes_p = ifelse(sum(.$no_fit_count) == 0, 1, sum(.$fit_count) / sum(.$total_count))
    ) %>%
    mutate(Parameter = "T_I_PPC")
  )



p<-ggplot(T_I_PPC, aes(x = T_I, y = T_I, color=section)) +
  facet_grid(cols=vars(section)) +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0) +
  labs(x = "Observed T_I", y = "95% PPI") +
  geom_line(color="black") +
  ylim(0, max(T_I_PPC$`97.5%`)) +
  xlim(0, max(T_I_PPC$`97.5%`))

ggsave(filename=file.path(here("fishery_analyses", params$project_name, params$fishery_name), "T_I_PPC.png"),
       plot = p,
       width = 6.5, height = 6.5, dpi = 300, limitsize = TRUE,
       scale=1.75,
       units = c("in")
       )

E_s_PPC<-as.data.frame(apply(extract(stan_fit)$E_s_rep,2, function(x) quantile(x, c(0.025,0.975))))%>%
  rownames_to_column(var="Quantile")%>%
  as_tibble()%>%
  pivot_longer(names_to = "names",values_to = "E_s",cols = c(-Quantile))%>%
  pivot_wider(names_from = Quantile,values_from = E_s)%>%
  bind_cols(tibble(E_s=inputs_bss[[ecg]]$E_s,
                   section=inputs_bss[[ecg]]$section_E,
                   day = inputs_bss[[ecg]]$day_E,
                   gear = inputs_bss[[ecg]]$gear_E,
                   countnum = inputs_bss[[ecg]]$countnum_E
                   )
  )%>%
  mutate(section = as.factor(section),
         day = as.factor(day),
         gear= as.factor(gear),
         countnum = as.factor(countnum),
         fit = factor(ifelse(E_s>=`2.5%` & E_s<=`97.5%`,"fit","no fit"))
         )
bayes_p<-bayes_p%>%
  bind_rows(E_s_PPC %>%
    group_by(section, gear) %>%
    summarise(
      fit_count = sum(fit == "fit"),
      no_fit_count = sum(fit == "no fit"),
      total_count = fit_count + no_fit_count,
      bayes_p = ifelse(no_fit_count == 0, 1, fit_count / total_count)
    ) %>%
    ungroup()%>%
    add_row(section = "Total", gear ="Total",
            fit_count = sum(.$fit_count),
            no_fit_count = sum(.$no_fit_count),
            total_count = sum(.$total_count),
            bayes_p = ifelse(sum(.$no_fit_count) == 0, 1, sum(.$fit_count) / sum(.$total_count))
    ) %>%
    mutate(Parameter = "E_s_PPC")
  )



p<-ggplot(E_s_PPC, aes(x = E_s, y = E_s, color=section, groups=gear)) +
  facet_grid(cols=vars(section),rows=vars(gear)) +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0) +
  labs(x = "Observed E_s", y = "95% PPI") +
  geom_line(color="black") +
  ylim(0, max(E_s_PPC$`97.5%`)) +
  xlim(0, max(E_s_PPC$`97.5%`))

ggsave(filename=file.path(here("fishery_analyses", params$project_name, params$fishery_name), "E_s_PPC.png"),
       plot = p,
       width = 6.5, height = 6.5, dpi = 300, limitsize = TRUE,
       scale=1.75,
       units = c("in")
       )


c_PPC<-as.data.frame(apply(extract(stan_fit)$c_rep,2, function(x) quantile(x, c(0.025,0.975))))%>%
  rownames_to_column(var="Quantile")%>%
  as_tibble()%>%
  pivot_longer(names_to = "names",values_to = "c",cols = c(-Quantile))%>%
  pivot_wider(names_from = Quantile,values_from = c)%>%
  bind_cols(tibble(c=inputs_bss[[ecg]]$c,
                   section=inputs_bss[[ecg]]$section_IntC,
                   day = inputs_bss[[ecg]]$day_IntC,
                   gear = inputs_bss[[ecg]]$gear_IntC,
                   )
  )%>%
  mutate(section = as.factor(section),
         day = as.factor(day),
         gear= as.factor(gear),
         fit = ifelse(c>=`2.5%` & c<=`97.5%`,"fit","no fit")
         )
bayes_p<-bayes_p%>%
  bind_rows(c_PPC%>%
    group_by(section, gear) %>%
    summarise(
      fit_count = sum(fit == "fit"),
      no_fit_count = sum(fit == "no fit"),
      total_count = fit_count + no_fit_count,
      bayes_p = ifelse(no_fit_count == 0, 1, fit_count / total_count)
    ) %>%
    ungroup()%>%
    add_row(section = "Total", gear ="Total",
            fit_count = sum(.$fit_count),
            no_fit_count = sum(.$no_fit_count),
            total_count = sum(.$total_count),
            bayes_p = ifelse(sum(.$no_fit_count) == 0, 1, sum(.$fit_count) / sum(.$total_count))
    )%>%
    mutate(Parameter = "c_PPC")
  )



p<-ggplot(c_PPC, aes(x = c+1, y = c+1, color=factor(fit), groups=interaction(gear,section))) +
  facet_grid(cols=vars(section),rows=vars(gear)) +
  geom_errorbar(aes(ymin = `2.5%` + 1, ymax = `97.5%` + 1), width = 0,position = position_jitter(width = 0.1, height=0)) +
  labs(x = "Observed E_s", y = "95% PPI") +
  geom_line(color="black") +
  scale_x_log10()+
  scale_y_log10()
  #ylim(1, max(c_PPC$`97.5%`)) +
  #xlim(1, max(c_PPC$`97.5%`))
ggsave(filename=file.path(here("fishery_analyses", params$project_name, params$fishery_name), "c_PPC.png"),
       plot = p,
       width = 6.5, height = 6.5, dpi = 300, limitsize = TRUE,
       scale=1.75,
       units = c("in")
       )


V_A_PPC<-as.data.frame(apply(extract(stan_fit)$V_A_rep,2, function(x) quantile(x, c(0.025,0.975))))%>%
  rownames_to_column(var="Quantile")%>%
  as_tibble()%>%
  pivot_longer(names_to = "names",values_to = "V_A",cols = c(-Quantile))%>%
  pivot_wider(names_from = Quantile,values_from = V_A)%>%
  bind_cols(tibble(V_A=inputs_bss[[ecg]]$V_A,
                   gear = inputs_bss[[ecg]]$gear_IntA
                   )
  )%>%
  mutate(gear= as.factor(gear),
         fit = factor(ifelse(V_A>=`2.5%` & V_A<=`97.5%`,"fit","no fit"))
         )

bayes_p<-bayes_p%>%
  bind_rows(V_A_PPC %>%
    group_by(gear) %>%
    summarise(
      fit_count = sum(fit == "fit"),
      no_fit_count = sum(fit == "no fit"),
      total_count = fit_count + no_fit_count,
      bayes_p = ifelse(no_fit_count == 0, 1, fit_count / total_count)
    ) %>%
    ungroup()%>%
    add_row(gear ="Total",
            fit_count = sum(.$fit_count),
            no_fit_count = sum(.$no_fit_count),
            total_count = sum(.$total_count),
            bayes_p = ifelse(sum(.$no_fit_count) == 0, 1, sum(.$fit_count) / sum(.$total_count))
    )%>%
    mutate(Parameter = "V_A_PPC")
  )


p<-ggplot(V_A_PPC, aes(x = V_A, y = V_A,colors=gear)) +
  facet_grid(cols=vars(gear)) +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0) +
  labs(x = "Observed E_s", y = "95% PPI") +
  geom_line(color="black") +
  ylim(0, max(V_A_PPC$`97.5%`)) +
  xlim(0, max(V_A_PPC$`97.5%`))

ggsave(filename=file.path(here("fishery_analyses", params$project_name, params$fishery_name), "V_A_PPC.png"),
       plot = p,
       width = 6.5, height = 6.5, dpi = 300, limitsize = TRUE,
       scale=1.75,
       units = c("in")
       )


T_A_PPC<-as.data.frame(apply(extract(stan_fit)$T_A_rep,2, function(x) quantile(x, c(0.025,0.975))))%>%
  rownames_to_column(var="Quantile")%>%
  as_tibble()%>%
  pivot_longer(names_to = "names",values_to = "T_A",cols = c(-Quantile))%>%
  pivot_wider(names_from = Quantile,values_from = T_A)%>%
  bind_cols(tibble(T_A=inputs_bss[[ecg]]$T_A,
                   gear = inputs_bss[[ecg]]$gear_IntA
                   )
  )%>%
  mutate(gear= as.factor(gear),
         fit = factor(ifelse(T_A>=`2.5%` & T_A<=`97.5%`,"fit","no fit"))
         )


bayes_p<-bayes_p%>%
  bind_rows(T_A_PPC %>%
    group_by(gear) %>%
    summarise(
      fit_count = sum(fit == "fit"),
      no_fit_count = sum(fit == "no fit"),
      total_count = fit_count + no_fit_count,
      bayes_p = ifelse(no_fit_count == 0, 1, fit_count / total_count)
    )%>%
    ungroup()%>%
    add_row(gear = "Total", 
            fit_count = sum(.$fit_count),
            no_fit_count = sum(.$no_fit_count),
            total_count = sum(.$total_count),
            bayes_p = ifelse(sum(.$no_fit_count) == 0, 1, sum(.$fit_count) / sum(.$total_count))
    ) %>%
    mutate(Parameter = "T_A_PPC")
  )


p<-ggplot(T_A_PPC, aes(x = T_A, y = T_A,colors=gear)) +
  facet_grid(cols=vars(gear)) +
  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`), width = 0) +
  labs(x = "Observed E_s", y = "95% PPI") +
  geom_line(color="black") +
  ylim(0, max(T_A_PPC$`97.5%`)) +
  xlim(0, max(T_A_PPC$`97.5%`))

ggsave(filename=file.path(here("fishery_analyses", params$project_name, params$fishery_name), "T_A_PPC.png"),
       plot = p,
       width = 6.5, height = 6.5, dpi = 300, limitsize = TRUE,
       scale=1.75,
       units = c("in")
       )

bayes_p%>%
  dplyr::select(Parameter,
                Section = section,
                Gear = gear,
                `Fit count` = fit_count,
                `No fit count` = no_fit_count,
                `Total n` = total_count,
                `p-value` = bayes_p
                )%>%
  #kableExtra::kbl()%>%
  #kableExtra::kable_classic(font="Times New Roman")%>%
  write.csv(file.path(here("fishery_analyses", params$project_name, params$fishery_name), "Bayes_p.csv"),row.names=F)


```


## Pre-season Fishery Planning
This section displays the pre-season Skagit wild winter steelhead run-size forecast, the exploitation rate matrix prescribed by the Resource Management Plan, and uses the two to calculate the allowable harvest. It then compares the planned harvest (sport fishery catch * assumed catch and release mortality rate) with the allowable harvest to estimate the percent of the allowable harvest the sport fishery will use as well as the probability that the sport fishery will exceed various percentages of the allowable impacts.

First, the allowable harvest rates in the RMP are:
```{r message = FALSE, warning = FALSE,results = "asis",include=TRUE, echo=FALSE}
hcr<-read_csv(file.path(here("fishery_analyses", params$project_name, params$fishery_name),"hcr.csv"))
hcr%>%mutate(MaxRunsize=format(MaxRunsize, scientific = FALSE))%>%
  rename(`Exploitation Rate` = ER, `Minimum Run Size` = MinRunsize,`Maximum Run Size` = MaxRunsize)%>%
  kableExtra::kbl(caption = "Table 1. Allowable Harvest Rates, Skagit RMP ",digits =3)%>%
  kableExtra::kable_classic(full_width = F, html_font = "Cambria")
```

The run size forecast is below, and is reprinted from the co-manager agreed-to [**pre-season forecast**](https://github.com/tbuehrens/Skagit-River-Steelhead-Forecast/blob/master/analysis/App_2_Model_fitting_forecast_2020_2021_step_head_fcst.pdf). A published scientific paper describing the methods may be found here: [**(preseason forecast publication)**](https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/1365-2664.13789).

For more details on how this forecast was developed, see this [**GitHub repository**](https://github.com/casruff/Skagit-River-Steelhead-Forecast), which is collaboratively maintained by tribal Co-Managers & WDFW.

```{r include=TRUE, fig.align="center", fig.cap=c("Figure 1. Skagit Steelhead Run-size Forecast. The forecast is shown as a 'bell curve' (though not symmetric), where the height of the curve is proportional to the probability that the true value (catch or effort) is equal to a particular value on the x-axis. The 'best' value is the 50th percentile, shown as a dashed line."),echo=FALSE}
runsize<-read_csv("https://raw.github.com/tbuehrens/Skagit-River-Steelhead-Forecast/master/analysis/cache/ensemble_forecast_posterior.csv")
ggplot(data=runsize,aes(x=ensemble_forecast_posterior))+
  geom_density(fill="forest green")+
  geom_vline(data=runsize,mapping=aes(xintercept=median(ensemble_forecast_posterior)),linetype="dashed")+
  xlab("Forecasted Run-Size")+
  theme_bw()

runsize%>%
  summarise(`Run Size` = round(quantile(ensemble_forecast_posterior, c(0.025, 0.25, 0.5,0.75, 0.975))), q = c(0.025,0.25, 0.5,0.75, 0.975)*100)%>%
  dplyr::rename(Percentile=q)%>%
  kableExtra::kbl(caption = "Table 2. Runsize Forecast. The 'best' estimate is the median or 50th percentile. The table shows the forecast percentiles, which represent the probability that the true run-size will fall below a particular value. For example, there is a 50% probability the true run size will be below the 50th percentile of the forecast.",digits =3,format = "html", table.attr = "style='width:40%;'")%>%
  kableExtra::kable_classic(html_font = "Cambria")
```

### Fishery Impacts Relative to Resource Management Plan Limits: Preseason Plan
Below you will find a comparison of the the planned sport fishery catch, assuming 10 percent catch and release mortality, with the allowable harvest based on the run size forecast and the RMP mortality limits.

The allowable harvest, according to the RMP, is the number of fish that may be killed by the combined sport and tribal fisheries. However, as seen above, this number depends on the run-size, which fishery managers will not know until after the fishing season when they estimate escapement. However, based on the pre-season forecast run size, we can estimate what the true allowable harvest will be by combining the forecast run size, including its uncertainty, with the harvest rate matrix prescribed by the RMP. We can then plot the probability that the true allowable harvest will exceed a range of values. The true allowable harvest will be known with more certainty after the season when the actual run-size is known and the appropriate harvest rate from the matrix can be multiplied by the actual run size.

For example, in 2021 there is a greater than 90 percent chance that the true allowable harvest based on the true run size and the harvest matrix, will exceed 100 fish. There is a 50% chance that the allowable harvest will exceed 430 fish (10 percent of the best estimate of the run-size from the forecast), and a very small chance the allowable harvest will be greater than 2,000 fish:
```{r include=TRUE, fig.align="center", fig.cap=c("Figure 2. Probability that the allowable harvest exceeds a particular number of fish based on the RMP. Note the log10 scale on the x-axis."),echo=FALSE}
ER_func<-function(hcr,runsize){
  ER<-c(NULL)
  indexes<-c(NULL)
  for(i in 1:nrow(hcr)){
    runsize=round(runsize)
    min<-hcr$MinRunsize[i]
    max<-hcr$MaxRunsize[i]
    ind<-which(min <= runsize & runsize <= max)
    indexes<-c(indexes,ind)
    ER<-c(ER,rep(hcr$ER[i],length(ind)))
    ERdat<-data.frame(indexes,ER)
  }
 return(ERdat)
}
ER<-ER_func(hcr=hcr,runsize=runsize)
AH<-data.frame(ER$ER,runsize)
AH$AH<-AH$ER.ER*AH$ensemble_forecast_posterior
AH$Exceedence<-rev(sort(percent_rank(AH$AH)))
#hist(AH$AH,breaks=seq(0,max(AH$AH)*1.1,100))

breaks <- 10^(-10:10)
minor_breaks <- rep(1:9, 21)*(10^rep(-10:10, each=9))
ggplot(data=AH,aes(x=AH,y=Exceedence))+
  geom_line(size=1.25)+
  theme_bw()+
  scale_x_log10(breaks = breaks, minor_breaks = minor_breaks)+
  annotation_logticks(base = 10,sides = "b")+
  coord_equal() +
  ylab("Probability of Exceedance")+
  xlab("Allowable (State + Tribal) Co-manager Harvest (fish)")
```

Given the uncertainty in what the allowable harvest will turn out to be, managers must balance the risk of exceeding the allowable harvest with the cost of erring so heavily on the side of conservation (to ensure the allowable harvest is not exceeded) that no fishery is allowed at all. To assist with this task, managers can plan a fishery to harvest a particular number of fish (which itself may be estimated with uncertainty) and then calculate the probability that the allowable harvest will turn out to have been exceeded if the planned fishery is implemented.

For example, in 2021, a four-day a week fishery was planned with a projected total harvest of 76 fish (760 wild fish handled * assumed 10 percent catch and release mortality rate). If the actual catch matches the projection exactly, this would translate to 18 percent of the allowable (sport and tribal) harvest under the RMP if the true allowable harvest is 430 (which is the best estimate from the preseason forecast, and corresponds to the 50% exceedance probability).

```{r include=TRUE, fig.align="center", fig.cap=c("Figure 3. Probability that the pre-season planned sport fishery harvest exceeds the allowable harvest (expressed as percentages) under the RMP. Vertical lines denote 50 percent of the allowable harvest, which is shared between the state and tribes, and 100 percent of the allowable harvest. The best estimate of the percent of the allowable harvest that will be used by the sport fishery is located on the graph where the probability of exceedance is 50 percent."),echo=FALSE}
preseason_planned_mortalities<-76
H_plan<-rlnorm(1000,log(preseason_planned_mortalities),0.1)
PAH_plan<-(sample(H_plan,10000,replace = T)/sample(AH$AH,10000,replace = T))*100
PAHdat_plan<-data.frame(PAH_plan,percent_rank(-PAH_plan))%>%rename(Exceedence="percent_rank..PAH_plan.")
ggplot(data=PAHdat_plan,aes(x=PAH_plan,y=Exceedence))+
  geom_line(size=1.25)+
  theme_bw()+
  ylab("Probability of Exceedance")+
  xlab("% of Allowable (Sport + Tribal) Co-Manager Harvest")+
  geom_vline(xintercept=50)+
  geom_vline(xintercept=100,col="red")
```
```{r include=TRUE, fig.align="center", fig.cap=c("Figure 4. Pre-season Planned Probability that the sport fishery harvest exceeds 50 and 100 percent of the allowable harvest under the RMP, as well as the best estimate of the percentage of allowable impacts the sport fishery will use"),echo=FALSE}
probs<-c(PAHdat_plan$PAH_plan[which(abs(PAHdat_plan$Exceedence - 0.5)==min(abs(PAHdat_plan$Exceedence - 0.5)))],
  PAHdat_plan$Exceedence[which(abs(PAHdat_plan$PAH - 50)==min(abs(PAHdat_plan$PAH - 50)))]*100,
  PAHdat_plan$Exceedence[which(abs(PAHdat_plan$PAH - 100)==min(abs(PAHdat_plan$PAH - 100)))]*100
  )
par(mar=c(5,15,5,5))
names(probs)<-c("best estimate of sport \nfishery impacts as \n % of total (sport + tribal) \n allowable","probability sport fishery \n impacts > 50% of total \n (sport + tribal) allowable","probability sport fishery \n impacts > 100% of total \n (sport + tribal) allowable")
barplot(probs,horiz = T,xlim=c(0,100),las=2,yaxs="i",col="forest green",main="Pre-season Plan"
        )
box()
```

## In-season Fishery Results

WDFW fishery managers use data from creel surveys to estimate the season total and daily catch and effort, and the daily catch per unit effort (CPUE). Results presented below include data collected through: **`r format(as.Date(all.Dates$Date[nrow(all.Dates)]), '%m/%d/%Y')`**

### Disclaimer
Contents on this page should be treated as preliminary and are subject to change. While every effort has been made to ensure the accuracy of data and modeling here, some numbers may change. Particularly in-season catch and effort estimates may change as additional data becomes available, and as data errors are corrected.

### Season Total Effort and Catch

This table and the figures below it show estimates of the season total catch and effort. Estimates are shown as 'bell curves' (though not symmetric), where the height of the curve is proportional to the probability that the true value (catch or effort) is equal to a particular value on the x-axis. The "best" estimate is the 50th percentile (median) in the table, and is denoted by the middle dashed line in the graphs:
```{r run_resid_analysis, message = FALSE, warning = FALSE,results = "asis",include=TRUE, echo=FALSE}
estimates_bss %>%
  map_df(~ .x$overview) %>%
  kableExtra::kbl(caption = "Table 3. Total Catch (fish) and Effort (hours). The 'best' estimate is the median or 50th percentile. The table shows the percentiles of estimated catch and effort, which represent the probability that the true catch or effort is below a particular value. For example, there is a 50% probability the true catch is below the 50th percentile of the estimated catch in this table.", digits = 1) %>%
  kableExtra::kable_classic(full_width = FALSE, html_font = "Cambria")
```


```{r, include=TRUE, fig.align="center", fig.cap=c("Figure 5. Season total catch (fish) and effort (angler hours). The middle dashed line shows the posterior median or 'best' estimate. Outer dashed lines show 95 percent credible intervals."),echo=FALSE,warning = FALSE}
res<-rstan::extract(stan_fit)

season_results<-data.frame(res$C_sum,res$E_sum)%>%
  mutate(iter=row_number())%>%
  rename(`Season Total Catch`=res.C_sum,`Season Total Effort`=res.E_sum)%>%
  pivot_longer(names_to = "Parameter",values_to="value",cols=c(`Season Total Catch`,`Season Total Effort`))

#elimiminate very very extreme quantiles to pretty up plots
lims<-season_results%>%group_by(Parameter)%>%summarise(value = quantile(value, c(0, 0.99)), q = c(0,0.99))%>%pivot_wider(names_from = q,values_from=value)

season_results_trunc=season_results%>%left_join(lims,by="Parameter")%>%filter(value>as.numeric(`0`) & value < as.numeric(`0.99`))

ggplot(season_results_trunc,aes(x=value,fill=Parameter))+
  facet_wrap(~Parameter,ncol=1,  scales = 'free')+
  theme_bw()+
  geom_density()+
  ylab(NULL)+
  geom_vline(season_results%>%group_by(Parameter)%>%summarise(value = quantile(value, c(0.025, 0.5, 0.975)), q = c(0.025, 0.5, 0.975)),mapping=aes(xintercept=value,group=Parameter),linetype="dashed")+
  theme(legend.title = element_blank())

```

### Daily Catch, Effort, and Catch Per Unit Effort
Below, you will find an estimate of the daily catch (fish), effort (hours), and catch per unit effort (fish/hr). The lines are the "best" estimates and the shading shows the 95 percent credible intervals (which are obtained from the statistical model used to estimate catch).
```{r, include=TRUE, fig.align="center", fig.cap=c("Figure 6. Daily catch. Lines are posterior medians or 'best' estimates, while shading shows 95% credible intervals."),echo=FALSE,warning = FALSE}
closed.Dates.DF<-closed.Dates.DF%>%
  pivot_longer(cols=c("Skagit","Sauk"))%>%
  rename(Section=name,closure=value)

Catch.summary<-Catch.summary%>%
  left_join(closed.Dates.DF,by=c("Date","Section"))%>%
  mutate(closure=ifelse(is.na(closure),"Open","Closed"))#%>%
  #mutate(Median=ifelse(closure=="Open",Median,NA),Mean=ifelse(closure=="Open",Mean,NA),l95=ifelse(closure=="Open",l95,NA),u95=ifelse(closure=="Open",u95,NA))

ggplot(Catch.summary,aes(x=as.Date(Date),y=Median,col=as.factor(Gear)))+
  facet_wrap(~Section,ncol=1)+
  geom_line(size=1.2)+
  ylab(paste0("Catch - ",catch.group.of.interest," (fish)"))+
  xlab("")+
  scale_x_date(date_labels = "%b-%d",date_breaks = "weeks")+
  geom_ribbon(aes(ymin=l95, ymax=u95,fill=as.factor(Gear)),alpha=0.2,col=NA)+
  #geom_rect(Catch.summary%>%filter(closure=="Closed"),mapping=aes(xmin = as.Date(Date)-0.5, xmax = as.Date(Date)+0.5, fill = as.factor(closure)),color=NA, ymin = -Inf, ymax = Inf, alpha = 1,fill="grey90")+
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90),legend.title = element_blank())
```

<!-- ```{r, include=TRUE, fig.align="center", fig.cap=c("Figure 7. Daily effort. Lines are posterior medians or 'best' estimates, while shading shows 95% credible intervals."), echo=FALSE,warning=F} -->
<!-- Effort.summary<-Effort.summary%>% -->
<!--   left_join(closed.Dates.DF,by=c("Date","Section"))%>% -->
<!--   mutate(closure=ifelse(is.na(closure),"Open","Closed"))#%>% -->
<!--   #mutate(Median=ifelse(closure=="Open",Median,NA),Mean=ifelse(closure=="Open",Mean,NA),l95=ifelse(closure=="Open",l95,NA),u95=ifelse(closure=="Open",u95,NA)) -->
<!-- ggplot(Effort.summary,aes(x=as.Date(Date),y=Median,col=as.factor(Gear)))+ -->
<!--   facet_wrap(~Section,ncol=1)+ -->
<!--   geom_line(size=1.2)+ -->
<!--   ylab("Angling Effort (hrs)")+ -->
<!--   xlab("")+ -->
<!--   scale_x_date(date_labels = "%b-%d",date_breaks = "weeks")+ -->
<!--   geom_ribbon(aes(ymin=l95, ymax=u95,fill=as.factor(Gear)),alpha=0.2,col=NA)+ -->
<!--   #geom_rect(Effort.summary%>%filter(closure=="Closed"),mapping=aes(xmin = as.Date(Date)-0.5, xmax = as.Date(Date)+0.5, fill = as.factor(closure)),color=NA, ymin = -Inf, ymax = Inf, alpha = 0.2,fill="grey80")+ -->
<!--   theme_bw()+ -->
<!--   theme(axis.text.x = element_text(angle = 90),legend.title = element_blank()) -->
<!-- ``` -->

<!-- ```{r, include=TRUE, fig.align="center", fig.cap=c("Figure 8. Daily CPUE. Lines are posterior medians or 'best' estimates, while shading shows 95% credible intervals."),echo=FALSE,warning=F} -->
<!-- CPUE.summary<-CPUE.summary%>% -->
<!--   left_join(closed.Dates.DF,by=c("Date","Section"))%>% -->
<!--   mutate(closure=ifelse(is.na(closure),"Open","Closed"))#%>% -->
<!--   #mutate(Median=ifelse(closure=="Open",Median,NA),Mean=ifelse(closure=="Open",Mean,NA),l95=ifelse(closure=="Open",l95,NA),u95=ifelse(closure=="Open",u95,NA)) -->
<!-- ggplot(CPUE.summary,aes(x=as.Date(Date),y=Median,col=as.factor(Gear)))+ -->
<!--   facet_wrap(~Section,ncol=1)+ -->
<!--   geom_line(size=1.2)+ -->
<!--   ylab("Catch Per Unit Effort (fish/hrs)")+ -->
<!--   xlab("")+ -->
<!--   scale_x_date(date_labels = "%b-%d",date_breaks = "weeks")+ -->
<!--   geom_ribbon(aes(ymin=l95, ymax=u95,fill=as.factor(Gear)),alpha=0.2,col=NA)+ -->
<!--   #geom_rect(CPUE.summary%>%filter(closure=="Closed"),mapping=aes(xmin = as.Date(Date)-0.5, xmax = as.Date(Date)+0.5, fill = as.factor(closure)),color=NA, ymin = -Inf, ymax = Inf, alpha = 0.2,fill="grey80")+ -->
<!--   theme_bw()+ -->
<!--   theme(axis.text.x = element_text(angle = 90),legend.title = element_blank()) -->
<!-- ``` -->

<!-- ### In-season Impact Monitoring: Fishery Impacts Relative to Resource Management Plan Limits -->
<!-- Here, we compare the actual in-season estimated sport fishery catch, assuming 10% C&R mortality, with the allowable harvest estimated from the forecasted run size and the RMP mortality limits, to estimate the probability that the allowable harvest has been exceeded by the actual fishery (as opposed to the pre-season plan that we looked at previously). Early in the season when little catch has occurred, the probability that the allowable harvest has been exceeded is low, but increases as the season goes on. This analyis enables an in-season quantification of risk by managers, which may be helpful in decision-making: -->
<!-- ```{r include=TRUE, fig.align="center", fig.cap=c("Figure 9. Probability that the actual in-season estimated sport fishery harvest exceeds the allowable harvest (expressed as percentages) under the RMP. Vertical lines denote 50 percent of the allowable harvest, which is shared between the state and tribes, and 100 percent of the allowable harvest. The best in-season estimate of the percent of the allowable harvest that has been used by the sport fishery is located on the graph where the probability of exceedance is 50 percent."),echo=FALSE,warning=F} -->
<!-- H<-res$C_sum*0.1 -->
<!-- PAH<-(sample(H,10000,replace = T)/sample(AH$AH,10000,replace = T))*100 -->
<!-- PAHdat<-data.frame(PAH,percent_rank(-PAH))%>%rename(Exceedence="percent_rank..PAH.") -->
<!-- ggplot(data=PAHdat,aes(x=PAH,y=Exceedence))+ -->
<!--   geom_line(size=1.25)+ -->
<!--   theme_bw()+ -->
<!--   ylab("Probability of Exceedance")+ -->
<!--   xlab("% of Allowable (Sport + Tribal) Co-Manager Harvest")+ -->
<!--   xlim(0,max(quantile(PAHdat$PAH,0.99),100))+ -->
<!--   geom_vline(xintercept=50)+ -->
<!--   geom_vline(xintercept=100,col="red") -->
<!-- ``` -->

<!-- ```{r include=TRUE, fig.align="center", fig.cap=c("Figure 10. Probability that the sport fishery harvest exceeds 50 and 100 percent of the allowable harvest under the RMP, as well as the best estimate of the percentage of allowable impacts the sport fishery will use."),echo=FALSE} -->
<!-- probs<-c(PAHdat$PAH[which(abs(PAHdat$Exceedence - 0.5)==min(abs(PAHdat$Exceedence - 0.5)))], -->
<!--   PAHdat$Exceedence[which(abs(PAHdat$PAH - 50)==min(abs(PAHdat$PAH - 50)))]*100, -->
<!--   PAHdat$Exceedence[which(abs(PAHdat$PAH - 100)==min(abs(PAHdat$PAH - 100)))]*100 -->
<!--   ) -->
<!-- par(mar=c(5,15,5,5)) -->
<!-- names(probs)<-c("best estimate of sport \nfishery impacts as \n % of total (sport + tribal) \n allowable","probability sport fishery \n impacts > 50% of total \n (sport + tribal) allowable","probability sport fishery \n impacts > 100% of total \n (sport + tribal) allowable") -->
<!-- barplot(probs,horiz = T,xlim=c(0,100),las=2,yaxs="i",col="forest green", main="In-season Estimate" -->
<!--         ) -->
<!-- box() -->
<!-- ``` -->





